#Trick 1 - Conditional Selection of Rows

# The conditional selection of rows can be based on a single condition or multiple conditions in a single statement separated by logical operators.

import pandas as pd

data = pd.read_csv('loan_train.csv')
print(data[['Education', 'ApplicantIncome']].head())

print('\n\nConditional Selection of Rows\n\n')

data_2 = data.loc[(data['Education'] == 'Not Graduate') & (data['ApplicantIncome'] <= 5400)]

print('\n\nFiltered Data\n\n')
print(data_2[['Education', 'ApplicantIncome']].head())

#Trick 2 - Binning of Data
# There are many variable types in python, you have continuous, discreet or categorical - many times, for purpose of meaningful analysis - it will be necessary to convert between variable types
# For instance creating age groups - Todlers, Pre-teens, Teens, Young Adults, Adults and so on from a list of supplied age ranges

#For instance, you have a continuous variable in your data – age. But you require an age group for your analysis such as – child, teenager, adult, senior citizen. Indeed, Binning is perfect to solve our problem here.

#To perform binning, we use the cut() function. This useful for going from a continuous variable to a categorical variable.

import pandas as pd

df = pd.read_csv('titanic.csv')
from sklearn.utils import shuffle

# Shuffling the Dataset
df = shuffle(df, random_state = 42)

df.head()

bins = [0,4,17,65,99]
labels =['Toddler','Child','Adult','Elderly']

category = pd.cut(df['Age'], bins = bins, labels = labels)

df.insert(2, 'Age Group', category)

df.head()

df['Age Group'].value_counts()

df.isnull().sum()


#Trick 3 - GroupBy
#Pandas provide an essential function to perform grouping of data which is Groupby.
#The Groupby operation involves the splitting of an object based on certain conditions, applying a function, and then combining the results.

#Groupby is one of the most frequent ops performed on data in data science

### Trick 3 - GroupBy

# Average Income of males and females
df3 = df2.groupby(['Gender'])[['ApplicantIncome']].mean()
print(df3.head(10))

# Average loan amount for different property areas like urban, rural
df4 = df2.groupby(['Property_Area'])[['LoanAmount']].mean()
print(df4.head())

# Compare loan status of different education backgrounds
df5 = df2.groupby(['Education'])[['Loan_Status']].count()
print(df5.head(10))

#Trick 4 - map - data substitution
#sample data
data = {'name': ['A', 'B', 'C', 'D', 'E'], 
        'age': [22, 26, 33, 44, 50],
        'profession' : ['data engineer', 'data scientist', 'entrepreneur', 'business analyst', 'self-employed'], 
        'city': ['Gurgaon', 'Bangalore', 'Gurgaon', 'Pune', 'New Delhi']}

df6 = pd.DataFrame(data)
print(df6.head())

# dictionary to map city with states
map_city_to_states = { 'Gurgaon' : 'Haryana', 
                  'Bangalore' : 'Karnataka', 
                  'Pune' : 'Maharashtra', 
                  'New Delhi' : 'Delhi'}

# apply pandas map to map the city columns with states
df6['state'] = df6['city'].map(map_city_to_states)
print(df6.head())

#Trick 5 - Styling The Dataframe
# Sometimes we just like to add visual perspective to our work

data = pd.read_excel("../data/salesman_performance.xlsx")
data

data.style

def highlight_green(sales):
    color = 'green' if sales > 80 else 'black'
    return 'color: %s' % color

formatting = data.iloc[:,1:6].style.applymap(highlight_green)
formatting
